{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eine Day-ahead Prognose f체r den deutschen Strommarkt\n",
    "### Mittels Zeitreihen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow.keras import Sequential\n",
    "from keras.layers import Dense,LSTM,Dropout, GRU, Activation, SimpleRNN\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math as m\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from pytictoc import TicToc\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Smard Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"price_data.csv\",sep=\",\",index_col=0)\n",
    "df.index = pd.to_datetime(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellung von Funktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(length, dataset):\n",
    "    \"Aufteilung Dataset in Train und Test\"\n",
    "    train,test=dataset[:length],dataset[length:]\n",
    "    return(train, test)\n",
    "\n",
    "\n",
    "def dataset_preparing(inputs,outputs, dataset):\n",
    "    \" Teilt das Dataset in Inputvektoren und Outputvektoren ein\"\n",
    "    x_i=[]\n",
    "    y_i=[]\n",
    "    for i in range(inputs,len(dataset)-outputs,outputs):\n",
    "        x_i.append(dataset[i-inputs:i])\n",
    "        y_i.append(dataset[i:i+outputs])\n",
    "    return np.array(x_i), np.array(y_i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daten skalieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "df=scaler.fit_transform(df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datenset in Trainings und Test daten unterteilen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=split_dataset(36000,df)[0]\n",
    "test=split_dataset(36000,df)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainings- und Testdaten in Input/Outputvekoren einteilen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= dataset_preparing(48,24,train)[0]\n",
    "Y_train=dataset_preparing(48,24,train)[1]\n",
    "X_test=dataset_preparing(48,24,test)[0]\n",
    "Y_test=dataset_preparing(48,24,test)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape der Vektoren in 3 Dimensionen 채ndern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.reshape(Y_train, (Y_train.shape[0], Y_train.shape[1]))\n",
    "Y_test=np.reshape(Y_test,(Y_test.shape[0],Y_test.shape[1]))\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
    "X_test=np.reshape(X_test,(X_test.shape[0],X_test.shape[1],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuronale Netze mit nur einer Schicht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_RNN1 =  Sequential()\n",
    "model_RNN1.add(SimpleRNN(units=24,input_shape=(X_train.shape[1], X_train.shape[2]),return_sequences=False,activation= \"relu\")) \n",
    "optimizer = RMSprop(lr=0.0001)\n",
    "model_RNN1.compile(loss='mae', optimizer=optimizer, metrics=['mean_squared_error'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min',patience=10,restore_best_weights=True)\n",
    "\n",
    "history_RNN1 = model_RNN1.fit(X_train, Y_train, epochs=200,batch_size=220, validation_data=(X_test,Y_test),shuffle=False,callbacks=[es])\n",
    "model_RNN1.summary() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model1 =  Sequential()\n",
    "model1.add(LSTM(units=24,input_shape=(X_train.shape[1], X_train.shape[2]),return_sequences=False,activation= \"relu\"))  \n",
    "\n",
    "optimizer = RMSprop(lr=0.0001)\n",
    "model1.compile( optimizer=optimizer, loss='mae',metrics=['mean_squared_error'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min',patience=10,restore_best_weights=True)\n",
    "\n",
    "history_lstm1 = model1.fit(X_train, Y_train, epochs=200,batch_size=220, validation_data=(X_test,Y_test),shuffle=False,callbacks=[es])\n",
    "model1.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_GRU1 =  Sequential()\n",
    "model_GRU1.add(GRU(units=24,input_shape=(X_train.shape[1], X_train.shape[2]),return_sequences=False,activation=\"relu\"))\n",
    "optimizer = RMSprop(lr=0.0001)\n",
    "model_GRU1.compile(loss='mae', optimizer=optimizer, metrics=['mean_squared_error'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min',patience=10,restore_best_weights=True)\n",
    "\n",
    "history_GRU1 = model_GRU1.fit(X_train, Y_train, epochs=200, batch_size=220,validation_data=(X_test,Y_test),shuffle=False,callbacks=[es])\n",
    "\n",
    "model_GRU1.summary() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prognosen der einfachen Netze erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_RNN1 = model_RNN1.predict(X_test)\n",
    "predict_RNN1 = scaler.inverse_transform(predict_RNN1)\n",
    "\n",
    "predict_lstm1 = model1.predict(X_test)\n",
    "predict_lstm1 = scaler.inverse_transform(predict_lstm1)\n",
    "\n",
    "test_predict_GRU1 = model_GRU1.predict(X_test)\n",
    "test_predict_GRU1 = scaler.inverse_transform(test_predict_GRU1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuronale Netze mit vier Schichten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_RNN =  Sequential()\n",
    "model_RNN.add(SimpleRNN(units=220,input_shape=(X_train.shape[1], X_train.shape[2]),return_sequences=True,activation= \"relu\")) \n",
    "model_RNN.add(Dropout(0.5))\n",
    "model_RNN.add(SimpleRNN(units=140,return_sequences=True,activation= \"relu\")) \n",
    "model_RNN.add(Dropout(0.5))\n",
    "model_RNN.add(SimpleRNN(units=80,return_sequences=True,activation= \"relu\"))\n",
    "model_RNN.add(Dropout(0.3))\n",
    "model_RNN.add(SimpleRNN(24, activation= \"relu\"))  \n",
    "model_RNN.compile(loss='mae', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min',patience=10,restore_best_weights=True)\n",
    "\n",
    "history_RNN = model_RNN.fit(X_train, Y_train, epochs=200,batch_size=220, validation_data=(X_test,Y_test),shuffle=False,callbacks=[es])\n",
    "model_RNN.summary() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model =  Sequential()\n",
    "model.add(LSTM(units=220,input_shape=(X_train.shape[1], X_train.shape[2]),return_sequences=True,activation= \"relu\")) \n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=140,return_sequences=True,activation= \"relu\")) \n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=80,return_sequences=True,activation= \"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(24, activation= \"relu\"))  \n",
    "model.compile(loss='mae', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min',patience=10,restore_best_weights=True)\n",
    "\n",
    "history_lstm = model.fit(X_train, Y_train, epochs=200,batch_size=220, validation_data=(X_test,Y_test),shuffle=False,callbacks=[es])\n",
    "model.summary() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_GRU =  Sequential()\n",
    "model_GRU.add(GRU(units=220,input_shape=(X_train.shape[1], X_train.shape[2]),return_sequences=True,activation=\"relu\")) \n",
    "model_GRU.add(Dropout(0.5))\n",
    "model_GRU.add(GRU(units=140,return_sequences=True,activation=\"relu\"))\n",
    "model_GRU.add(Dropout(0.5))\n",
    "model_GRU.add(GRU(units=80,return_sequences=True,activation=\"relu\"))\n",
    "model_GRU.add(Dropout(0.3))\n",
    "model_GRU.add(GRU(24,activation=\"relu\"))\n",
    "model_GRU.compile(loss='mae', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min',patience=10,restore_best_weights=True)\n",
    "\n",
    "history_GRU = model_GRU.fit(X_train, Y_train, epochs=200, batch_size=220,validation_data=(X_test,Y_test),shuffle=False,callbacks=[es])\n",
    "model_GRU.summary() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fehlerfunktionen anzeigen lassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"Trainings und Test Fehler\")\n",
    "plt.xlabel(\"Epoche\")\n",
    "plt.plot(history_GRU.history[\"loss\"])\n",
    "plt.plot(history_GRU.history[\"val_loss\"])\n",
    "plt.plot(history_RNN.history[\"loss\"])\n",
    "plt.plot(history_RNN.history[\"val_loss\"])\n",
    "plt.plot(history_lstm.history[\"loss\"])\n",
    "plt.plot(history_lstm.history[\"val_loss\"])\n",
    "plt.legend([\"GRU Train loss\",\"GRU Test loss\", \"RNN Train loss\",\"RNN Test loss\",\"LSTM train loss\", \"LSTM Test loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prognosen erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_RNN = model_RNN.predict(X_test)\n",
    "predict_RNN = scaler.inverse_transform(predict_RNN)\n",
    "\n",
    "predict_lstm = model.predict(X_test)\n",
    "predict_lstm = scaler.inverse_transform(predict_lstm)\n",
    "\n",
    "test_predict_GRU = model_GRU.predict(X_test)\n",
    "test_predict_GRU = scaler.inverse_transform(test_predict_GRU)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zur체ck skalierung der Test Outputwerte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_test = scaler.inverse_transform(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modellg체te (MAE) berechnen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Multi Layer LSTM hat ein MAE von {}\".format(round(mean_absolute_error(Y_test,predict_lstm),2)))\n",
    "print(\"Multi Layer GRU hat ein MAE von {}\".format(round(mean_absolute_error(Y_test,test_predict_GRU),2)))\n",
    "print(\"Multi Layer RNN hat ein MAE von {}\".format(round(mean_absolute_error(Y_test,predict_RNN),2)))\n",
    "print(\"Single Layer LSTM hat ein MAE von {}\".format(round(mean_absolute_error(Y_test,predict_lstm1),2)))\n",
    "print(\"Single Layer GRU hat ein MAE von {}\".format(round(mean_absolute_error(Y_test,test_predict_GRU1),2)))\n",
    "print(\"Single Layer RNN hat ein MAE von {}\".format(round(mean_absolute_error(Y_test,predict_RNN1),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ergebnisse anzeigen lassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.title(\"LSTM Model 2020-06-29 MAE: {}\".format(round(mean_absolute_error(Y_test[-1],predict_lstm[-1])),2))\n",
    "plt.ylabel('Electricity price', size=15)\n",
    "plt.xlabel('Time', size=15)\n",
    "plt.plot(Y_test[:][-1],marker=\"x\")\n",
    "plt.plot(predict_lstm[:][-1], marker=\"x\")\n",
    "plt.legend([\"Test Price\",\"Predictions LSTM\"],loc=\"best\",prop={'size': 12})\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.title(\"GRU Model 2020-06-29 MAE: {}\".format(round(mean_absolute_error(Y_test[-1],test_predict_GRU[-1])),2))\n",
    "plt.ylabel('Electricity price', size=15)\n",
    "plt.xlabel('Time', size=15)\n",
    "plt.plot(Y_test[:][-1],marker=\"x\")\n",
    "plt.plot(test_predict_GRU[:][-1], marker=\"x\")\n",
    "plt.legend([\"Test Price\",\"Predictions GRU\"],loc=\"best\",prop={'size': 12})\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
